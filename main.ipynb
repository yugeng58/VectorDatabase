{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c007b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最近邻索引: [[482 994 944 913 338]]\n",
      "距离: [[5.7352233 5.9523897 5.9794054 6.031189  6.267953 ]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "d = 64  \n",
    "nb = 1000 \n",
    "np.random.seed(123)\n",
    "db_vectors = np.random.random((nb, d)).astype('float32')\n",
    "query = np.random.random((1, d)).astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(d)  \n",
    "index.add(db_vectors)  \n",
    "D, I = index.search(query, k=5)  \n",
    "print(\"最近邻索引:\", I)\n",
    "print(\"距离:\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95844c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embedded vector: (3, 384)\n",
      "similarity:\n",
      " [[0.99999976 0.6290454  0.45318767]\n",
      " [0.6290454  0.99999994 0.6113744 ]\n",
      " [0.45318767 0.6113744  0.99999976]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "sentences = [\"this is a sample sentence\", \"another sentence\", \"totally different sentence\"]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(\"shape of embedded vector:\", embeddings.shape) \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(embeddings)\n",
    "print(\"similarity:\\n\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b23ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.86it/s]]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 175.77it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询结果:\n",
      "距离: 0.4142, 元数据: {'id': 0, 'text': '人工智能（AI）是计算机科学的一个分支，旨在创建能够执行需要人类智能的任务的系统，例如学习、问题解决、决策和感知。近年来，AI 技术在自然语言处理、计算机视觉和机器人领域取得了显著进展。', 'extra': {'category': 'AI Overview'}}\n",
      "距离: 0.4142, 元数据: {'id': 3, 'text': '人工智能（AI）是计算机科学的一个分支，旨在创建能够执行需要人类智能的任务的系统，例如学习、问题解决、决策和感知。近年来，AI 技术在自然语言处理、计算机视觉和机器人领域取得了显著进展。', 'extra': {'category': 'AI Overview'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 145.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "删除后查询结果:\n",
      "距离: 0.4142, 元数据: {'id': 0, 'text': '人工智能（AI）是计算机科学的一个分支，旨在创建能够执行需要人类智能的任务的系统，例如学习、问题解决、决策和感知。近年来，AI 技术在自然语言处理、计算机视觉和机器人领域取得了显著进展。', 'extra': {'category': 'AI Overview'}}\n",
      "距离: 0.4142, 元数据: {'id': 3, 'text': '人工智能（AI）是计算机科学的一个分支，旨在创建能够执行需要人类智能的任务的系统，例如学习、问题解决、决策和感知。近年来，AI 技术在自然语言处理、计算机视觉和机器人领域取得了显著进展。', 'extra': {'category': 'AI Overview'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "class VectorDatabase:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', index_path='faiss_index.bin', metadata_path='metadata.json', max_seq_length=512):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.model.max_seq_length = max_seq_length   \n",
    "        self.dimension = self.model.get_sentence_embedding_dimension() \n",
    "        self.index = faiss.IndexFlatL2(self.dimension)  \n",
    "        self.index_path = index_path\n",
    "        self.metadata_path = metadata_path\n",
    "        self.metadata = []  \n",
    "        self.next_id = 0\n",
    "        self.load()\n",
    "\n",
    "    def add(self, texts, metadata=None):\n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=True,\n",
    "            batch_size=16\n",
    "        ).astype('float32')\n",
    "\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "        if metadata is None:\n",
    "            metadata = [{} for _ in texts]\n",
    "        for i, text in enumerate(texts):\n",
    "            self.metadata.append({\n",
    "                'id': self.next_id,\n",
    "                'text': text,\n",
    "                'extra': metadata[i]\n",
    "            })\n",
    "            self.next_id += 1\n",
    "\n",
    "        self.save()\n",
    "\n",
    "    def search(self, query_text, k=5):\n",
    "        query_embedding = self.model.encode(\n",
    "            [query_text],\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=True,\n",
    "            batch_size=1\n",
    "        ).astype('float32')\n",
    "\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "\n",
    "        results = []\n",
    "        for idx, dist in zip(indices[0], distances[0]):\n",
    "            if idx != -1 and idx < len(self.metadata):\n",
    "                results.append({\n",
    "                    'distance': float(dist),\n",
    "                    'metadata': self.metadata[idx]\n",
    "                })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def delete(self, id):\n",
    "        if id in [m['id'] for m in self.metadata]:\n",
    "            self.metadata = [m for m in self.metadata if m['id'] != id]\n",
    "\n",
    "            embeddings = self.model.encode(\n",
    "                [m['text'] for m in self.metadata],\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True,\n",
    "                show_progress_bar=True,\n",
    "                batch_size=16\n",
    "            ).astype('float32')\n",
    "            self.index = faiss.IndexFlatL2(self.dimension)\n",
    "            if len(embeddings) > 0:\n",
    "                self.index.add(embeddings)\n",
    "\n",
    "            self.save()\n",
    "\n",
    "    def save(self):\n",
    "        faiss.write_index(self.index, self.index_path)\n",
    "        with open(self.metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def load(self):\n",
    "        if os.path.exists(self.index_path):\n",
    "            self.index = faiss.read_index(self.index_path)\n",
    "        if os.path.exists(self.metadata_path):\n",
    "            try:\n",
    "                with open(self.metadata_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read().strip()\n",
    "                    if content:\n",
    "                        self.metadata = json.loads(content)\n",
    "                        self.next_id = max([m['id'] for m in self.metadata], default=-1) + 1\n",
    "                    else:\n",
    "                        self.metadata = []\n",
    "                        self.next_id = 0\n",
    "            except Exception as e:\n",
    "                print(f\"加载元数据文件出错: {e}, 已重置为空.\")\n",
    "                self.metadata = []\n",
    "                self.next_id = 0\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化数据库\n",
    "    db = VectorDatabase(\n",
    "        model_name='all-MiniLM-L6-v2',\n",
    "        index_path='vector_db_index.bin',\n",
    "        metadata_path='vector_db_metadata.json',\n",
    "        max_seq_length=512\n",
    "    )\n",
    "\n",
    "    # 添加大段中文文本\n",
    "    texts = [\n",
    "        \"人工智能（AI）是计算机科学的一个分支，旨在创建能够执行需要人类智能的任务的系统，例如学习、问题解决、决策和感知。近年来，AI 技术在自然语言处理、计算机视觉和机器人领域取得了显著进展。\",\n",
    "        \"机器学习是人工智能的核心子领域，它使计算机能够通过数据和经验进行学习，而无需明确的编程。监督学习、无监督学习和强化学习是机器学习的主要类型。\",\n",
    "        \"深度学习是一种基于人工神经网络的机器学习技术，广泛应用于图像识别、语音处理和自然语言处理。深度学习的成功得益于大数据、强大的计算能力和优化的算法。\"\n",
    "    ]\n",
    "    metadata = [\n",
    "        {'category': 'AI Overview'},\n",
    "        {'category': 'Machine Learning'},\n",
    "        {'category': 'Deep Learning'}\n",
    "    ]\n",
    "    db.add(texts, metadata)\n",
    "\n",
    "    # 查询\n",
    "    query = \"人工智能技术如何影响自然语言处理？\"\n",
    "    results = db.search(query, k=2)\n",
    "    print(\"查询结果:\")\n",
    "    for result in results:\n",
    "        print(f\"距离: {result['distance']:.4f}, 元数据: {result['metadata']}\")\n",
    "\n",
    "    # 删除（示例）\n",
    "    db.delete(1)  # 删除 ID 为 1 的记录\n",
    "\n",
    "    # 再次查询\n",
    "    results = db.search(query, k=2)\n",
    "    print(\"\\n删除后查询结果:\")\n",
    "    for result in results:\n",
    "        print(f\"距离: {result['distance']:.4f}, 元数据: {result['metadata']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
